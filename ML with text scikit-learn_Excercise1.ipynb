{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following model I developed, by following the [Data School Course](https://github.com/justmarkham/pycon-2016-tutorial). In the course, Kevin describes the deveoplment of the Machine learning model for text. In his tutorial, Kevin only used count vectorizer method for vectorization and multinomial Naive Bayes model for building the model. However, I try to to do something different. Instead of one I used two vectorization methods and two machine learning model. later then I used confusion matrix approach to comapre the different models accuracy. In the end, I presented which naive bays model works well with two different vectorizer method. \n",
    "\n",
    "PS: I'm new-bie in data science area. So, I beleive I have made mistakes, If so your valuable response will help me to grow. In the end, I want to Thank Kavin for the wonderful and clearly description of this tutorial.\n",
    "\n",
    "Thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Task 1: Get familier with the data\n",
    "#Import the necessary libraries\n",
    "#Read yelp.csv into a pandas DataFrame and examine it\n",
    "#Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python libraries for exploring and manipulating data\n",
    "\n",
    "# Libraries for data analysis and data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Python libraries for visualization\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# save filepath and read file into pandas from a URL for easier access\n",
    "url  = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/yelp.csv'\n",
    "\n",
    "# read the data and store data in DataFrame titled yelp\n",
    "yelp = pd.read_csv(url)\n",
    "\n",
    "# Examine the shape of the data set\n",
    "print(yelp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 5 rows of the yelp data\n",
    "yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>is-olmqaSZ0KCoe-_ftW5w</td>\n",
       "      <td>2011-03-21</td>\n",
       "      <td>_0Y6QAT1dBOVmYOXIoVpKw</td>\n",
       "      <td>4</td>\n",
       "      <td>Tough to rank this place...   it is a retireme...</td>\n",
       "      <td>review</td>\n",
       "      <td>LZZNgNIuA2W4mn-5LLH24g</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>KBG28p3lGX17hOPoHhq5PQ</td>\n",
       "      <td>2008-02-15</td>\n",
       "      <td>o1twR2pI5yE6xE0HnRGnIQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Sushi is not just a meal, it's an experience.....</td>\n",
       "      <td>review</td>\n",
       "      <td>GZFiCRwm-bVauSRtTKhb4g</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9469</th>\n",
       "      <td>SjFl_V6BTGkmv4tbub-AVw</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>XeD6j_ItpmuTjas2Z8A1rw</td>\n",
       "      <td>4</td>\n",
       "      <td>PBR. Mad Dog 20/20. What??!! I was a witness t...</td>\n",
       "      <td>review</td>\n",
       "      <td>ZqMS4ElQg-k1tQBC06h7lQ</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>LMG0zsAkUSscIvmV9vvm3A</td>\n",
       "      <td>2010-09-21</td>\n",
       "      <td>QyHVsAOYH-vIdiIqpYS8dg</td>\n",
       "      <td>5</td>\n",
       "      <td>I just celebrated my birthday at Oregano's.  I...</td>\n",
       "      <td>review</td>\n",
       "      <td>OjPYJxpkm_xDIiZAquMEIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>1crzPdwnlm2zHdQ2nP4n7w</td>\n",
       "      <td>2011-02-08</td>\n",
       "      <td>HZvzvZaXpp7q-tIaI2QBaA</td>\n",
       "      <td>5</td>\n",
       "      <td>Imagine a white silk wedding dress.... black! ...</td>\n",
       "      <td>review</td>\n",
       "      <td>PNS9z4aFDbfhpIsHCfNvNg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "8600  is-olmqaSZ0KCoe-_ftW5w  2011-03-21  _0Y6QAT1dBOVmYOXIoVpKw      4   \n",
       "6889  KBG28p3lGX17hOPoHhq5PQ  2008-02-15  o1twR2pI5yE6xE0HnRGnIQ      5   \n",
       "9469  SjFl_V6BTGkmv4tbub-AVw  2008-09-04  XeD6j_ItpmuTjas2Z8A1rw      4   \n",
       "3401  LMG0zsAkUSscIvmV9vvm3A  2010-09-21  QyHVsAOYH-vIdiIqpYS8dg      5   \n",
       "6072  1crzPdwnlm2zHdQ2nP4n7w  2011-02-08  HZvzvZaXpp7q-tIaI2QBaA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "8600  Tough to rank this place...   it is a retireme...  review   \n",
       "6889  Sushi is not just a meal, it's an experience.....  review   \n",
       "9469  PBR. Mad Dog 20/20. What??!! I was a witness t...  review   \n",
       "3401  I just celebrated my birthday at Oregano's.  I...  review   \n",
       "6072  Imagine a white silk wedding dress.... black! ...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "8600  LZZNgNIuA2W4mn-5LLH24g     0       0      0  \n",
       "6889  GZFiCRwm-bVauSRtTKhb4g     4       3      0  \n",
       "9469  ZqMS4ElQg-k1tQBC06h7lQ     6       6      3  \n",
       "3401  OjPYJxpkm_xDIiZAquMEIA     0       0      0  \n",
       "6072  PNS9z4aFDbfhpIsHCfNvNg     0       2      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the random 5 rows of the yelp data\n",
    "yelp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "9995  VY_tvNUCCXGXQeSvJl757Q  2012-07-28  Ubyfp2RSDYW0g7Mbr8N3iA      3   \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg  2012-01-18  2XyIOQKbVFb6uXQdJ0RzlQ      4   \n",
       "9997  53YGfwmbW73JhFiemNeyzQ  2010-11-16  jyznYkIbpqVmlsZxSDSypA      4   \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA  2012-12-02  5UKq9WQE1qQbJ0DJbc-B6Q      2   \n",
       "9999  pF7uRzygyZsltbmVpjIyvw  2010-10-16  vWSmOhg2ID1MNZHaWapGbA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow     1       2      0  \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw     0       0      0  \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg     0       0      0  \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ     0       0      0  \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA     0       0      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the last 5 rows of the yelp data\n",
    "yelp.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>CrBsdxqOjPdnfsDxV89GJQ</td>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>SmUMyCUNrT9HEo_DXdgUuQ</td>\n",
       "      <td>4</td>\n",
       "      <td>I have to admit that I find myself thinking th...</td>\n",
       "      <td>review</td>\n",
       "      <td>bZFRqP7s0Vszxeu8_IwYow</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>m9Wqqma30o-hH2fAX7dnug</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>oTB_mpCKcu-8wayQQuCDZw</td>\n",
       "      <td>5</td>\n",
       "      <td>Best food, super friendly staff, and great pri...</td>\n",
       "      <td>review</td>\n",
       "      <td>FpCmGLWHe5Y-kDS7ZYaF5w</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>M3zLQRbSF_VcGukkzxXc4w</td>\n",
       "      <td>2010-06-15</td>\n",
       "      <td>1e_YRoF0lrA9-4tvdym_Sg</td>\n",
       "      <td>5</td>\n",
       "      <td>Christy is an amazing cake artist.  She has an...</td>\n",
       "      <td>review</td>\n",
       "      <td>_w_hrcZ-9uObIBepDmLJwg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>LzpR_jE6VIutJ08s2cdRrw</td>\n",
       "      <td>2011-02-19</td>\n",
       "      <td>WqLc0KSfMHGoWNtvPque5w</td>\n",
       "      <td>4</td>\n",
       "      <td>OK, Sweet Pea and I love us some Coup, and it'...</td>\n",
       "      <td>review</td>\n",
       "      <td>GVH_iuoPc0aP3ZNYlWuKag</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>WaO_hAunQrZ--vI308rHQA</td>\n",
       "      <td>2011-06-06</td>\n",
       "      <td>4jkSNOjZN-35vo1_Z2SL7w</td>\n",
       "      <td>3</td>\n",
       "      <td>Great food and awesome service! Even better th...</td>\n",
       "      <td>review</td>\n",
       "      <td>qT17WVkJi0RvQ4nNPN6NDw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id        date               review_id  stars  \\\n",
       "100  CrBsdxqOjPdnfsDxV89GJQ  2010-02-17  SmUMyCUNrT9HEo_DXdgUuQ      4   \n",
       "101  m9Wqqma30o-hH2fAX7dnug  2011-03-14  oTB_mpCKcu-8wayQQuCDZw      5   \n",
       "102  M3zLQRbSF_VcGukkzxXc4w  2010-06-15  1e_YRoF0lrA9-4tvdym_Sg      5   \n",
       "103  LzpR_jE6VIutJ08s2cdRrw  2011-02-19  WqLc0KSfMHGoWNtvPque5w      4   \n",
       "104  WaO_hAunQrZ--vI308rHQA  2011-06-06  4jkSNOjZN-35vo1_Z2SL7w      3   \n",
       "\n",
       "                                                  text    type  \\\n",
       "100  I have to admit that I find myself thinking th...  review   \n",
       "101  Best food, super friendly staff, and great pri...  review   \n",
       "102  Christy is an amazing cake artist.  She has an...  review   \n",
       "103  OK, Sweet Pea and I love us some Coup, and it'...  review   \n",
       "104  Great food and awesome service! Even better th...  review   \n",
       "\n",
       "                    user_id  cool  useful  funny  \n",
       "100  bZFRqP7s0Vszxeu8_IwYow     0       1      0  \n",
       "101  FpCmGLWHe5Y-kDS7ZYaF5w     0       1      0  \n",
       "102  _w_hrcZ-9uObIBepDmLJwg     0       0      0  \n",
       "103  GVH_iuoPc0aP3ZNYlWuKag     0       0      0  \n",
       "104  qT17WVkJi0RvQ4nNPN6NDw     1       0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the choice of rows using slice index\n",
    "yelp[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      5  My wife took me here on my birthday for breakf...\n",
       "1      5  I have no idea why some people give bad review...\n",
       "2      4  love the gyro plate. Rice is so good and I als...\n",
       "3      5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4      5  General Manager Scott Petello is a good egg!!!..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp[['stars','text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "business_id    10000 non-null object\n",
      "date           10000 non-null object\n",
      "review_id      10000 non-null object\n",
      "stars          10000 non-null int64\n",
      "text           10000 non-null object\n",
      "type           10000 non-null object\n",
      "user_id        10000 non-null object\n",
      "cool           10000 non-null int64\n",
      "useful         10000 non-null int64\n",
      "funny          10000 non-null int64\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 781.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Examine the data type of all features and target\n",
    "print(yelp.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stars\n",
      "1    749\n",
      "2    927\n",
      "3   1461\n",
      "4   3526\n",
      "5   3337\n",
      "________________________________________\n",
      "   stars\n",
      "1    749\n",
      "2    927\n",
      "3   1461\n",
      "5   3337\n",
      "4   3526\n"
     ]
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "\n",
    "#sort_index will sort indexes\n",
    "sort_indexes = pd.DataFrame(yelp.stars.value_counts(dropna=False).sort_index())\n",
    "\n",
    "#sort_values will sort values\n",
    "sort_values = pd.DataFrame(yelp.stars.value_counts().sort_values())\n",
    "\n",
    "print(sort_indexes)\n",
    "print('_'*40)\n",
    "print(sort_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114fc4ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#yelp['stars'].value_counts().plot.bar()\n",
    "#sb.distplot(yelp['stars']);\n",
    "sb.countplot(yelp['stars'],);\n",
    "#code to remove outer line from the graph\n",
    "sb.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Create a new dataset\n",
    "#Create a new DataFrame that only contains the 5-star and 1-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9682</th>\n",
       "      <td>wzP2yNpV5p04nh0injjymA</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>OAn4Mio4vlY5VjTTug6kjQ</td>\n",
       "      <td>5</td>\n",
       "      <td>This is thee place to indulge your sweet tooth...</td>\n",
       "      <td>review</td>\n",
       "      <td>1zjPzcFdboSqis0Fkhccdg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>6Tt0mGKbMoAz1GsjkVhbMQ</td>\n",
       "      <td>2012-05-25</td>\n",
       "      <td>YTzrrPFgcC7DjAr2Qp8U2g</td>\n",
       "      <td>5</td>\n",
       "      <td>Really delicious breakfast burritos! They are ...</td>\n",
       "      <td>review</td>\n",
       "      <td>mVPISwK-W6gmlbR5oemOsQ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>Y-ci4KjSUdwfc6ru4XnX8Q</td>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>UlLg43QG5zJoKmq0t6PULQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Treated some clients to Sweet Pea Bakery items...</td>\n",
       "      <td>review</td>\n",
       "      <td>XBHJCDzNh--mBhJkzyM_iA</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>8HmSt7fRFe-uH6i4yCmJQQ</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>T3dnb2VW9IEE-aAYccG-rA</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this KFC ...or any really for th...</td>\n",
       "      <td>review</td>\n",
       "      <td>JkMOQaMjlBHMqp6gj-hL3w</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>pfTwzep_4hRTX_jXoi38cw</td>\n",
       "      <td>2011-06-02</td>\n",
       "      <td>OdzhxCxBxVkJjEJUDTI9oQ</td>\n",
       "      <td>1</td>\n",
       "      <td>The food was not particularly good on our last...</td>\n",
       "      <td>review</td>\n",
       "      <td>cxjTpWMPg7u5Bb9OPWqaFw</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>8t80-omyflkywRfu9LPh6g</td>\n",
       "      <td>2011-04-19</td>\n",
       "      <td>mEFozJbPZHUm6YQo-uGG2g</td>\n",
       "      <td>5</td>\n",
       "      <td>This is my favorite seafood place in Phoenix!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>X_kPh3nt0AJPNPHye2rTlA</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>QnAzW6KMSciUcuJ20oI3Bw</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>wcpepBjeZuz0cQKupbB_YA</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is great!!! They grow alot of the f...</td>\n",
       "      <td>review</td>\n",
       "      <td>47VCrr83Tvtkp1FvDa0ftQ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>L9UYbtAUOcfTgZFimehlXw</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>J5kIrC9Sx8il8DZkOhVOgQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Just perfect !!!  For what it is!!!  Down to t...</td>\n",
       "      <td>review</td>\n",
       "      <td>l2srZt-GNvF7tMotR_VyAw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>b5cEoKR8iQliq-yT2_O0LQ</td>\n",
       "      <td>2010-03-09</td>\n",
       "      <td>c7UBikwEOZfG2kTUQ3M3EA</td>\n",
       "      <td>5</td>\n",
       "      <td>Great surprise-- I have driven by this place s...</td>\n",
       "      <td>review</td>\n",
       "      <td>76SlIVfcXJujKQ3xSyYtOQ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>Tt6DYs0TyERWHWW5xiRL_A</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>oNWasO70MB71PSw00rN5vQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Yen has amazing sushi. I would say that they h...</td>\n",
       "      <td>review</td>\n",
       "      <td>IqrtFpXjwUhJNd28LUOOeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "9682  wzP2yNpV5p04nh0injjymA  2011-01-06  OAn4Mio4vlY5VjTTug6kjQ      5   \n",
       "7222  6Tt0mGKbMoAz1GsjkVhbMQ  2012-05-25  YTzrrPFgcC7DjAr2Qp8U2g      5   \n",
       "9558  Y-ci4KjSUdwfc6ru4XnX8Q  2008-06-03  UlLg43QG5zJoKmq0t6PULQ      5   \n",
       "4656  8HmSt7fRFe-uH6i4yCmJQQ  2008-09-04  T3dnb2VW9IEE-aAYccG-rA      1   \n",
       "5314  pfTwzep_4hRTX_jXoi38cw  2011-06-02  OdzhxCxBxVkJjEJUDTI9oQ      1   \n",
       "3091  8t80-omyflkywRfu9LPh6g  2011-04-19  mEFozJbPZHUm6YQo-uGG2g      5   \n",
       "9574  QnAzW6KMSciUcuJ20oI3Bw  2010-06-01  wcpepBjeZuz0cQKupbB_YA      5   \n",
       "798   L9UYbtAUOcfTgZFimehlXw  2011-07-27  J5kIrC9Sx8il8DZkOhVOgQ      5   \n",
       "9202  b5cEoKR8iQliq-yT2_O0LQ  2010-03-09  c7UBikwEOZfG2kTUQ3M3EA      5   \n",
       "7111  Tt6DYs0TyERWHWW5xiRL_A  2011-01-18  oNWasO70MB71PSw00rN5vQ      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "9682  This is thee place to indulge your sweet tooth...  review   \n",
       "7222  Really delicious breakfast burritos! They are ...  review   \n",
       "9558  Treated some clients to Sweet Pea Bakery items...  review   \n",
       "4656  I do not like this KFC ...or any really for th...  review   \n",
       "5314  The food was not particularly good on our last...  review   \n",
       "3091  This is my favorite seafood place in Phoenix!!...  review   \n",
       "9574  This place is great!!! They grow alot of the f...  review   \n",
       "798   Just perfect !!!  For what it is!!!  Down to t...  review   \n",
       "9202  Great surprise-- I have driven by this place s...  review   \n",
       "7111  Yen has amazing sushi. I would say that they h...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "9682  1zjPzcFdboSqis0Fkhccdg     0       0      0  \n",
       "7222  mVPISwK-W6gmlbR5oemOsQ     0       1      0  \n",
       "9558  XBHJCDzNh--mBhJkzyM_iA     2       3      0  \n",
       "4656  JkMOQaMjlBHMqp6gj-hL3w     1       2      0  \n",
       "5314  cxjTpWMPg7u5Bb9OPWqaFw     1       1      0  \n",
       "3091  X_kPh3nt0AJPNPHye2rTlA     2       3      0  \n",
       "9574  47VCrr83Tvtkp1FvDa0ftQ     2       0      0  \n",
       "798   l2srZt-GNvF7tMotR_VyAw     0       0      0  \n",
       "9202  76SlIVfcXJujKQ3xSyYtOQ     0       1      0  \n",
       "7111  IqrtFpXjwUhJNd28LUOOeg     0       0      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise will only classify worst rating(1 star) or best rating (5 star).hence, we will create a new \n",
    "#data frame which only contains the 5 star and 1 star review rating.\n",
    "yelp_worst_best = yelp[(yelp.stars == 5) | (yelp.stars == 1)]\n",
    "\n",
    "#examine the random 10 samples from the new data set \"yelp_worst_best\".\n",
    "yelp_worst_best.sample(10,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the shape of the new data set \"yelp_worst_best\".\n",
    "yelp_worst_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    3337\n",
      "1     749\n",
      "Name: stars, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fd7e410>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1fcd6bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# examine the class distribution for new data set \"yelp_worst_best\".\n",
    "print(yelp_worst_best.stars.value_counts(dropna= False))\n",
    "sb.countplot(yelp_worst_best.stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Splitting the dataset into X and y object \n",
    "#Define X and y from the new DataFrame\n",
    "#Split X and y into training and testing sets, using the review text as the only feature and the star rating as the response\n",
    "\n",
    "\n",
    "#Things to know: I have used here \"train_test_split\" methods\n",
    "\n",
    "In further steps I will use this method with 2 different vectorizarion methods i.e. \"CountVectorizer\" and \"TfidfVectorizer\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4086,)\n",
      "(4086,)\n"
     ]
    }
   ],
   "source": [
    "#define X and y (from the yelp_worst_best data set) for use with COUNTVECTORIZER\n",
    "X = yelp_worst_best.text\n",
    "y = yelp_worst_best.stars\n",
    "\n",
    "# Examine the shape of X and y before spliting the data set\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n",
      "(3064,)\n",
      "(1022,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ketansahu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "#Method 1: \"train_test_split\" method\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 1)\n",
    "\n",
    "# Examine the shape of object (X_tarin, X_test, y_train and y_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Vectorizing the dataset with different methods\n",
    "#Use CountVectorizer and TfidfVectorizer to create document-term matrices from X_train and X_test.\n",
    "\n",
    "#Things to know: I have used here 2 methods for vectorization.These methods are:\n",
    "\n",
    "Method 1: CountVectorizer (CV)\n",
    "\n",
    "Method 2: TfidfVectorizer (TV)\n",
    "\n",
    "\n",
    "In the model building and evaluation process, all above methods will be tested with MultinomialNB and Linear regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 1: CountVectorizer (by using train_test_split method)\n",
    "\n",
    "# import and instantiate CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# instantiate the vectorizer\n",
    "vect_CV = CountVectorizer()\n",
    "\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "# fit and transform X_train into X_train_dtm_CV\n",
    "X_train_dtm_CV = vect_CV.fit_transform(X_train)\n",
    "# examine the document-term matrix\n",
    "X_train_dtm_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 77006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "# transform X_test into X_test_dtm_CV\n",
    "X_test_dtm_CV = vect_CV.transform(X_test)\n",
    "X_test_dtm_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 2: TfidfVectorizer (by using train_test_split method)\n",
    "\n",
    "# import and instantiate TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# instantiate the vectorizer\n",
    "vect_TV = TfidfVectorizer()\n",
    "\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "# fit and transform X_train into X_train_dtm_TV\n",
    "X_train_dtm_TV = vect_TV.fit_transform(X_train)\n",
    "# examine the document-term matrix\n",
    "X_train_dtm_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16825 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 77006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "# transform X_test into X_test_dtm_TV\n",
    "X_test_dtm_TV = vect_TV.transform(X_test)\n",
    "X_test_dtm_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.fit(train) learns the vocabulary of the training data\n",
    "#vect.transform(train) uses the fitted vocabulary to build a document-term matrix from the training data\n",
    "#vect.transform(test) uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Building and evaluating a model\n",
    "#Use multinomial Naive Bayes to predict the star rating for the reviews in the testing set\n",
    "#Use Logistic Regression to compare the models\n",
    "#Calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# instantiate the MultinomialNB\n",
    "nb_CV= MultinomialNB()\n",
    "# train the model using X_train_dtm_CV and y_train\n",
    "nb_CV.fit(X_train_dtm_CV,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# instantiate the MultinomialNB\n",
    "nb_TV= MultinomialNB()\n",
    "# train the model using X_train_dtm_TV and y_train\n",
    "nb_TV.fit(X_train_dtm_TV,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the Logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# instantiate a logistic regression model\n",
    "logreg_CV= LogisticRegression()\n",
    "# train the model using X_train_dtm_CV and y_train\n",
    "logreg_CV.fit(X_train_dtm_CV,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the Logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# instantiate a logistic regression model\n",
    "logreg_TV= LogisticRegression()\n",
    "# train the model using X_train_dtm_TV and y_train\n",
    "logreg_TV.fit(X_train_dtm_TV,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Class prediction of count vectorizer based multinomialNB Model is', array([5, 5, 5, ..., 5, 1, 5]))\n",
      "________________________________________\n",
      "('The Class prediction of TfidfVectorizer based multinomialNB Model is', array([5, 5, 5, ..., 5, 5, 5]))\n",
      "________________________________________\n",
      "('The Class prediction of count vectorizer based Regression Model is', array([5, 1, 5, ..., 5, 1, 5]))\n",
      "________________________________________\n",
      "('The Class prediction of TfidfVectorizer based Regression Model is', array([5, 5, 5, ..., 5, 1, 5]))\n"
     ]
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm_CV and X_test_dtm_TV (for MultinomialNB and regression model )\n",
    "\n",
    "#MultinomialNB Model\n",
    "y_predict_class_nb_CV = nb_CV.predict(X_test_dtm_CV)\n",
    "print(\"The Class prediction of count vectorizer based multinomialNB Model is\",y_predict_class_nb_CV)\n",
    "print('_'*40)\n",
    "y_predict_class_nb_TV = nb_TV.predict(X_test_dtm_TV)\n",
    "print(\"The Class prediction of TfidfVectorizer based multinomialNB Model is\",y_predict_class_nb_TV)\n",
    "print('_'*40)\n",
    "\n",
    "#Regression model\n",
    "y_predict_class_logreg_CV = logreg_CV.predict(X_test_dtm_CV)\n",
    "print(\"The Class prediction of count vectorizer based Regression Model is\",y_predict_class_logreg_CV)\n",
    "print('_'*40)\n",
    "y_predict_class_logreg_TV = logreg_TV.predict(X_test_dtm_TV)\n",
    "print(\"The Class prediction of TfidfVectorizer based Regression Model is\",y_predict_class_logreg_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classification accuracy of count vectorizer based multinomialNB Model is:', 0.9187866927592955)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification accuracy of TfidfVectorizer based multinomialNB Model is', 0.8199608610567515)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification accuracy of count vectorizer based Regression Model is', 0.9256360078277887)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification accuracy of TfidfVectorizer based Regression Model is', 0.8199608610567515)\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy of class predictions (for MultinomialNB and regression model )\n",
    "#Classification accuracy: percentage of correct predictions\n",
    "from sklearn import metrics\n",
    "\n",
    "#MultinomialNB Model\n",
    "accuracy_MultinomialNB_CV = metrics.accuracy_score(y_test,y_predict_class_nb_CV)\n",
    "print(\"Classification accuracy of count vectorizer based multinomialNB Model is:\" ,accuracy_MultinomialNB_CV)\n",
    "print('_'*100)\n",
    "accuracy_MultinomialNB_TV = metrics.accuracy_score(y_test,y_predict_class_nb_TV)\n",
    "print(\"Classification accuracy of TfidfVectorizer based multinomialNB Model is\",accuracy_MultinomialNB_TV)\n",
    "print('_'*100)\n",
    "#Regression model\n",
    "accuracy_Regression_CV = metrics.accuracy_score(y_test,y_predict_class_logreg_CV)\n",
    "print(\"Classification accuracy of count vectorizer based Regression Model is\",accuracy_Regression_CV)\n",
    "print('_'*100)\n",
    "accuracy_MultinomialNB_TV = metrics.accuracy_score(y_test,y_predict_class_nb_TV)\n",
    "print(\"Classification accuracy of TfidfVectorizer based Regression Model is\",accuracy_MultinomialNB_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#null accuracy \n",
    "#accuracy that could be achieved by always predicting the most frequent class\n",
    "\n",
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.819961\n",
      "Name: stars, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a21160d10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a211607d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "#max(y_test.mean(), 1 - y_test.mean())\n",
    "# calculate null accuracy (for multi-class classification problems)\n",
    "print(y_test.value_counts().head(1) / len(y_test))\n",
    "(y_test.value_counts().head(1) / len(y_test)).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizer based multinomialNB Model\n",
      "('True:', array([5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 1, 1, 1]))\n",
      "('Pred:', array([5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 1]))\n",
      "____________________________________________________________________________________________________\n",
      "TfidfVectorizer based multinomialNB Model\n",
      "('True:', array([5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 1, 1, 1]))\n",
      "('Pred:', array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]))\n",
      "____________________________________________________________________________________________________\n",
      "Count vectorizer based regression Model\n",
      "('True:', array([5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 1, 1, 1]))\n",
      "('Pred:', array([5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 1, 5]))\n",
      "____________________________________________________________________________________________________\n",
      "TfidfVectorizer based regression Model\n",
      "('True:', array([5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 1, 1, 1]))\n",
      "('Pred:', array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]))\n"
     ]
    }
   ],
   "source": [
    "# print the first 20 true and predicted responses (for MultinomialNB and regression model )\n",
    "\n",
    "#MultinomialNB Model\n",
    "print(\"Count vectorizer based multinomialNB Model\")\n",
    "print('True:',y_test.values[0:20])\n",
    "print('Pred:',y_predict_class_nb_CV[0:20])\n",
    "print('_'*100)\n",
    "print(\"TfidfVectorizer based multinomialNB Model\")\n",
    "print('True:',y_test.values[0:20])\n",
    "print('Pred:',y_predict_class_nb_TV[0:20])\n",
    "print('_'*100)\n",
    "#Regression model\n",
    "print(\"Count vectorizer based regression Model\")\n",
    "print('True:',y_test.values[0:20])\n",
    "print('Pred:',y_predict_class_logreg_CV[0:20])\n",
    "print('_'*100)\n",
    "print(\"TfidfVectorizer based regression Model\")\n",
    "print('True:',y_test.values[0:20])\n",
    "print('Pred:',y_predict_class_nb_TV[0:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Examine the models with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  58]\n",
      " [ 25 813]]\n",
      "____________________________________________________________________________________________________\n",
      "[[  0 184]\n",
      " [  0 838]]\n",
      "____________________________________________________________________________________________________\n",
      "[[140  44]\n",
      " [ 32 806]]\n",
      "____________________________________________________________________________________________________\n",
      "[[ 82 102]\n",
      " [  9 829]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix (for MultinomialNB and regression model )\n",
    "\n",
    "#MultinomialNB Model\n",
    "confusion_MultinomialNB_CV= metrics.confusion_matrix(y_test, y_predict_class_nb_CV)\n",
    "print(confusion_MultinomialNB_CV)\n",
    "print('_'*100)\n",
    "confusion_MultinomialNB_TV= metrics.confusion_matrix(y_test, y_predict_class_nb_TV)\n",
    "print(confusion_MultinomialNB_TV)\n",
    "print('_'*100)\n",
    "#Regression model\n",
    "confusion_Regression_CV= metrics.confusion_matrix(y_test, y_predict_class_logreg_CV)\n",
    "print(confusion_Regression_CV)\n",
    "print('_'*100)\n",
    "confusion_Regression_TV= metrics.confusion_matrix(y_test, y_predict_class_logreg_TV)\n",
    "print(confusion_Regression_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces (for MultinomialNB and regression model )\n",
    "\n",
    "#MultinomialNB Model\n",
    "TP_MultinomialNB_CV = confusion_MultinomialNB_CV[1, 1]\n",
    "TN_MultinomialNB_CV = confusion_MultinomialNB_CV[0, 0]\n",
    "FP_MultinomialNB_CV = confusion_MultinomialNB_CV[0, 1]\n",
    "FN_MultinomialNB_CV = confusion_MultinomialNB_CV[1, 0]\n",
    "\n",
    "TP_MultinomialNB_TV = confusion_MultinomialNB_TV[1, 1]\n",
    "TN_MultinomialNB_TV = confusion_MultinomialNB_TV[0, 0]\n",
    "FP_MultinomialNB_TV = confusion_MultinomialNB_TV[0, 1]\n",
    "FN_MultinomialNB_TV = confusion_MultinomialNB_TV[1, 0]\n",
    "\n",
    "\n",
    "#Regression model\n",
    "TP_Regression_CV = confusion_Regression_CV[1, 1]\n",
    "TN_Regression_CV = confusion_Regression_CV[0, 0]\n",
    "FP_Regression_CV = confusion_Regression_CV[0, 1]\n",
    "FN_Regression_CV = confusion_Regression_CV[1, 0]\n",
    "\n",
    "TP_Regression_TV = confusion_Regression_TV[1, 1]\n",
    "TN_Regression_TV = confusion_Regression_TV[0, 0]\n",
    "FP_Regression_TV = confusion_Regression_TV[0, 1]\n",
    "FN_Regression_TV = confusion_Regression_TV[1, 0]\n",
    "\n",
    "\n",
    "#True Positives (TP): we correctly predicted that rating is 5 star\n",
    "#True Negatives (TN): we correctly predicted that rating is 1 star\n",
    "#False Positives (FP): we incorrectly predicted that rating is 5 star(a \"Type I error\")\n",
    "#False Negatives (FN): we incorrectly predicted that rating is 1 star (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classification accuracy of count vectorizer based multinomialNB Model is', 0.9187866927592955)\n",
      "('Classification accuracy of count vectorizer based multinomialNB Model is', 0.9187866927592955)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification accuracy of TfidfVectorizer based multinomialNB Model is', 0.8199608610567515)\n",
      "('Classification accuracy of TfidfVectorizer based multinomialNB Model is', 0.8199608610567515)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification accuracy of count vectorizer based regression Model is', 0.9256360078277887)\n",
      "('Classification accuracy of count vectorizer based regression Model is', 0.9256360078277887)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification accuracy of TfidfVectorizer based regression Model is', 0.8913894324853229)\n",
      "('Classification accuracy of TfidfVectorizer based regression Model is', 0.8913894324853229)\n"
     ]
    }
   ],
   "source": [
    "#Classification accuracy: (for MultinomialNB and regression model )\n",
    "#Overall, how often is the classifier correct?\n",
    "\n",
    "#MultinomialNB Model\n",
    "print(\"Classification accuracy of count vectorizer based multinomialNB Model is\",(TP_MultinomialNB_CV + TN_MultinomialNB_CV) / float(TP_MultinomialNB_CV + TN_MultinomialNB_CV + FP_MultinomialNB_CV + FN_MultinomialNB_CV))\n",
    "print(\"Classification accuracy of count vectorizer based multinomialNB Model is\",metrics.accuracy_score(y_test, y_predict_class_nb_CV))\n",
    "print('_'*100)\n",
    "print(\"Classification accuracy of TfidfVectorizer based multinomialNB Model is\",(TP_MultinomialNB_TV + TN_MultinomialNB_TV) / float(TP_MultinomialNB_TV + TN_MultinomialNB_TV + FP_MultinomialNB_TV + FN_MultinomialNB_TV))\n",
    "print(\"Classification accuracy of TfidfVectorizer based multinomialNB Model is\",metrics.accuracy_score(y_test, y_predict_class_nb_TV))\n",
    "print('_'*100)\n",
    "#Regression model\n",
    "print(\"Classification accuracy of count vectorizer based regression Model is\",(TP_Regression_CV + TN_Regression_CV) / float(TP_Regression_CV + TN_Regression_CV + FP_Regression_CV + FN_Regression_CV))\n",
    "print(\"Classification accuracy of count vectorizer based regression Model is\",metrics.accuracy_score(y_test, y_predict_class_logreg_CV))\n",
    "print('_'*100)\n",
    "print(\"Classification accuracy of TfidfVectorizer based regression Model is\",(TP_Regression_TV + TN_Regression_TV) / float(TP_Regression_TV + TN_Regression_TV + FP_Regression_TV + FN_Regression_TV))\n",
    "print(\"Classification accuracy of TfidfVectorizer based regression Model is\",metrics.accuracy_score(y_test, y_predict_class_logreg_TV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classification error of count vectorizer based multinomialNB Model is', 0.0812133072407045)\n",
      "('Classification error of count vectorizer based multinomialNB Model is', 0.08121330724070452)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification error of TfidfVectorizer based multinomialNB Model is', 0.18003913894324852)\n",
      "('Classification error of TfidfVectorizer based multinomialNB Model is', 0.18003913894324852)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification error of count vectorizer based regression Model is', 0.07436399217221135)\n",
      "('Classification error of count vectorizer based regression Model is', 0.07436399217221135)\n",
      "____________________________________________________________________________________________________\n",
      "('Classification error of TfidfVectorizer based regression Model is', 0.1086105675146771)\n",
      "('Classification error of TfidfVectorizer based regression Model is', 0.10861056751467713)\n"
     ]
    }
   ],
   "source": [
    "#Classification Error (for MultinomialNB and regression model )\n",
    "#Overall, how often is the classifier incorrect?, Also known as \"Misclassification Rate\"\n",
    "\n",
    "#MultinomialNB Model\n",
    "print(\"Classification error of count vectorizer based multinomialNB Model is\",(FP_MultinomialNB_CV + FN_MultinomialNB_CV) / float(TP_MultinomialNB_CV + TN_MultinomialNB_CV + FP_MultinomialNB_CV + FN_MultinomialNB_CV))\n",
    "print(\"Classification error of count vectorizer based multinomialNB Model is\",1 - metrics.accuracy_score(y_test, y_predict_class_nb_CV))\n",
    "print('_'*100)\n",
    "print(\"Classification error of TfidfVectorizer based multinomialNB Model is\",(FP_MultinomialNB_TV + FN_MultinomialNB_TV) / float(TP_MultinomialNB_TV + TN_MultinomialNB_TV + FP_MultinomialNB_TV + FN_MultinomialNB_TV))\n",
    "print(\"Classification error of TfidfVectorizer based multinomialNB Model is\",1 - metrics.accuracy_score(y_test, y_predict_class_nb_TV))\n",
    "print('_'*100)\n",
    "\n",
    "#Regression model\n",
    "print(\"Classification error of count vectorizer based regression Model is\",(FP_Regression_CV + FN_Regression_CV) / float(TP_Regression_CV + TN_Regression_CV + FP_Regression_CV + FN_Regression_CV))\n",
    "print(\"Classification error of count vectorizer based regression Model is\",1 - metrics.accuracy_score(y_test, y_predict_class_logreg_CV))\n",
    "print('_'*100)\n",
    "print(\"Classification error of TfidfVectorizer based regression Model is\",(FP_Regression_TV + FN_Regression_TV) / float(TP_Regression_TV + TN_Regression_TV + FP_Regression_TV + FN_Regression_TV))\n",
    "print(\"Classification error of TfidfVectorizer based regression Model is\",1 - metrics.accuracy_score(y_test, y_predict_class_logreg_TV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sensitivity of count vectorizer based multinomialNB Model is', 0.9701670644391408)\n",
      "('Sensitivity of count vectorizer based multinomialNB Model is', 0.6847826086956522)\n",
      "____________________________________________________________________________________________________\n",
      "('Sensitivity of TfidfVectorizer based multinomialNB Model is', 1.0)\n",
      "('Sensitivity of TfidfVectorizer based multinomialNB Model is', 0.0)\n",
      "____________________________________________________________________________________________________\n",
      "('Sensitivity of count vectorizer based regression Model is', 0.9618138424821002)\n",
      "('Sensitivity of count vectorizer based regression Model is', 0.7608695652173914)\n",
      "____________________________________________________________________________________________________\n",
      "('Sensitivity of TfidfVectorizer based regression Model is', 0.9892601431980907)\n",
      "('Sensitivity of TfidfVectorizer based regression Model is', 0.44565217391304346)\n"
     ]
    }
   ],
   "source": [
    "#sensitivity: (for MultinomialNB and regression model )\n",
    "#When the actual value is positive, how often is the prediction correct?, Also known as \"True Positive Rate\" or \"Recall\"\n",
    "print(\"Sensitivity of count vectorizer based multinomialNB Model is\",TP_MultinomialNB_CV / float(TP_MultinomialNB_CV + FN_MultinomialNB_CV))\n",
    "print(\"Sensitivity of count vectorizer based multinomialNB Model is\",metrics.recall_score(y_test, y_predict_class_nb_CV))\n",
    "print('_'*100)\n",
    "print(\"Sensitivity of TfidfVectorizer based multinomialNB Model is\",TP_MultinomialNB_TV / float(TP_MultinomialNB_TV + FN_MultinomialNB_TV))\n",
    "print(\"Sensitivity of TfidfVectorizer based multinomialNB Model is\",metrics.recall_score(y_test, y_predict_class_nb_TV))\n",
    "print('_'*100)\n",
    "print(\"Sensitivity of count vectorizer based regression Model is\",TP_Regression_CV / float(TP_Regression_CV + FN_Regression_CV))\n",
    "print(\"Sensitivity of count vectorizer based regression Model is\",metrics.recall_score(y_test, y_predict_class_logreg_CV))\n",
    "print('_'*100)\n",
    "print(\"Sensitivity of TfidfVectorizer based regression Model is\",TP_Regression_TV / float(TP_Regression_TV + FN_Regression_TV))\n",
    "print(\"Sensitivity of TfidfVectorizer based regression Model is\",metrics.recall_score(y_test, y_predict_class_logreg_TV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('False Negative Rate for count vectorizer based multinomialNB Model is', 0.029832935560859187)\n",
      "____________________________________________________________________________________________________\n",
      "('False Negative Rate for TfidfVectorizer based multinomialNB Model is', 0.0)\n",
      "____________________________________________________________________________________________________\n",
      "('False Negative Rate for count vectorizer based regression Model is', 0.03818615751789976)\n",
      "____________________________________________________________________________________________________\n",
      "('False Negative Rate for TfidfVectorizer based regression Model is', 0.010739856801909307)\n"
     ]
    }
   ],
   "source": [
    "#False Negative Rate \n",
    "print(\"False Negative Rate for count vectorizer based multinomialNB Model is\",FN_MultinomialNB_CV / float(TP_MultinomialNB_CV + FN_MultinomialNB_CV))\n",
    "print('_'*100)\n",
    "print(\"False Negative Rate for TfidfVectorizer based multinomialNB Model is\",FN_MultinomialNB_TV / float(TP_MultinomialNB_TV + FN_MultinomialNB_TV))\n",
    "print('_'*100)\n",
    "print(\"False Negative Rate for count vectorizer based regression Model is\",FN_Regression_CV / float(TP_Regression_CV + FN_Regression_CV))\n",
    "print('_'*100)\n",
    "print(\"False Negative Rate for TfidfVectorizer based regression Model is\",FN_Regression_TV / float(TP_Regression_TV + FN_Regression_TV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Precision for count vectorizer based multinomialNB Model is', 0.9334098737083811)\n",
      "('Precision for count vectorizer based multinomialNB Model is', 0.8344370860927153)\n",
      "____________________________________________________________________________________________________\n",
      "('Precision for TfidfVectorizer based multinomialNB Model is', 0.8199608610567515)\n",
      "('Precision for TfidfVectorizer based multinomialNB Model is', 0.0)\n",
      "____________________________________________________________________________________________________\n",
      "('Precision for count vectorizer based regression Model is', 0.9482352941176471)\n",
      "('Precision for count vectorizer based regression Model is', 0.813953488372093)\n",
      "____________________________________________________________________________________________________\n",
      "('Precision for TfidfVectorizer based regression Model is', 0.8904403866809882)\n",
      "('Precision for TfidfVectorizer based regression Model is', 0.9010989010989011)\n"
     ]
    }
   ],
   "source": [
    "#Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "print(\"Precision for count vectorizer based multinomialNB Model is\",TP_MultinomialNB_CV / float(TP_MultinomialNB_CV + FP_MultinomialNB_CV))\n",
    "print(\"Precision for count vectorizer based multinomialNB Model is\",metrics.precision_score(y_test, y_predict_class_nb_CV))\n",
    "print('_'*100)\n",
    "print(\"Precision for TfidfVectorizer based multinomialNB Model is\",TP_MultinomialNB_TV / float(TP_MultinomialNB_TV + FP_MultinomialNB_TV))\n",
    "print(\"Precision for TfidfVectorizer based multinomialNB Model is\",metrics.precision_score(y_test, y_predict_class_nb_TV))\n",
    "print('_'*100)\n",
    "print(\"Precision for count vectorizer based regression Model is\",TP_Regression_CV / float(TP_Regression_CV + FP_Regression_CV))\n",
    "print(\"Precision for count vectorizer based regression Model is\",metrics.precision_score(y_test, y_predict_class_logreg_CV))\n",
    "print('_'*100)\n",
    "print(\"Precision for TfidfVectorizer based regression Model is\",TP_Regression_TV / float(TP_Regression_TV + FP_Regression_TV))\n",
    "print(\"Precision for TfidfVectorizer based regression Model is\",metrics.precision_score(y_test, y_predict_class_logreg_TV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('specificity for count vectorizer based multinomialNB Model is', 0.6847826086956522)\n",
      "____________________________________________________________________________________________________\n",
      "('specificity for TfidfVectorizer based multinomialNB Model is', 0.0)\n",
      "____________________________________________________________________________________________________\n",
      "('specificity for count vectorizer based regression Model is', 0.7608695652173914)\n",
      "____________________________________________________________________________________________________\n",
      "('specificity for TfidfVectorizer based regression Model is', 0.44565217391304346)\n"
     ]
    }
   ],
   "source": [
    "#specificity : When the actual value is negative, how often is the prediction correct?\n",
    "print(\"specificity for count vectorizer based multinomialNB Model is\",TN_MultinomialNB_CV / float(TN_MultinomialNB_CV + FP_MultinomialNB_CV))\n",
    "print('_'*100)\n",
    "print(\"specificity for TfidfVectorizer based multinomialNB Model is\",TN_MultinomialNB_TV / float(TN_MultinomialNB_TV + FP_MultinomialNB_TV))\n",
    "print('_'*100)\n",
    "print(\"specificity for count vectorizer based regression Model is\",TN_Regression_CV / float(TN_Regression_CV + FP_Regression_CV))\n",
    "print('_'*100)\n",
    "print(\"specificity for TfidfVectorizer based regression Model is\",TN_Regression_TV / float(TN_Regression_TV + FP_Regression_TV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('False Positive Rate for count vectorizer based multinomialNB Model is', 0.31521739130434784)\n",
      "____________________________________________________________________________________________________\n",
      "('False Positive Rate for TfidfVectorizer based multinomialNB Model is', 1.0)\n",
      "____________________________________________________________________________________________________\n",
      "('False Positive Rate for count vectorizer based regression Model is', 0.2391304347826087)\n",
      "____________________________________________________________________________________________________\n",
      "('False Positive Rate for TfidfVectorizer based regression Model is', 0.5543478260869565)\n"
     ]
    }
   ],
   "source": [
    "#False Positive Rate : When the actual value is negative, how often is the prediction incorrect?\n",
    "print(\"False Positive Rate for count vectorizer based multinomialNB Model is\",FP_MultinomialNB_CV / float(TN_MultinomialNB_CV + FP_MultinomialNB_CV))\n",
    "print('_'*100)\n",
    "print(\"False Positive Rate for TfidfVectorizer based multinomialNB Model is\",FP_MultinomialNB_TV / float(TN_MultinomialNB_TV + FP_MultinomialNB_TV))\n",
    "print('_'*100)\n",
    "print(\"False Positive Rate for count vectorizer based regression Model is\",FP_Regression_CV / float(TN_Regression_CV + FP_Regression_CV))\n",
    "print('_'*100)\n",
    "print(\"False Positive Rate for TfidfVectorizer based regression Model is\",FP_Regression_TV / float(TN_Regression_TV + FP_Regression_TV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First 5 false positive ratings identified from count vectorizer based multinomialNB Model is',                                                    text\n",
      "2175  This has to be the worst restaurant in terms o...\n",
      "1781  If you like the stuck up Scottsdale vibe this ...\n",
      "2674  I'm sorry to be what seems to be the lone one ...\n",
      "9984  Went last night to Whore Foods to get basics t...\n",
      "3392  I found Lisa G's while driving through phoenix...)\n",
      "____________________________________________________________________________________________________\n",
      "('First 5 false positive ratings identified from TfidfVectorizer based multinomialNB Model is',                                                    text\n",
      "2175  This has to be the worst restaurant in terms o...\n",
      "4556  I ate at Scramble last Friday and I have to sa...\n",
      "1048  Went to Fatburger with our family tonight and ...\n",
      "1781  If you like the stuck up Scottsdale vibe this ...\n",
      "2674  I'm sorry to be what seems to be the lone one ...)\n",
      "____________________________________________________________________________________________________\n",
      "('First 5 false positive ratings identified from count vectorizer based regression Model is',                                                    text\n",
      "2175  This has to be the worst restaurant in terms o...\n",
      "1781  If you like the stuck up Scottsdale vibe this ...\n",
      "7913  Unprofessional, disorganized, and extremely lo...\n",
      "9984  Went last night to Whore Foods to get basics t...\n",
      "1212  Just had Daphnes for the last time. In the 3 t...)\n",
      "____________________________________________________________________________________________________\n",
      "('First 5 false positive ratings identified from TfidfVectorizer based regression Model is',                                                    text\n",
      "2175  This has to be the worst restaurant in terms o...\n",
      "1781  If you like the stuck up Scottsdale vibe this ...\n",
      "2674  I'm sorry to be what seems to be the lone one ...\n",
      "7913  Unprofessional, disorganized, and extremely lo...\n",
      "9984  Went last night to Whore Foods to get basics t...)\n"
     ]
    }
   ],
   "source": [
    "# first 5 false positives (1-star reviews incorrectly classified as 5-star reviews)\n",
    "print(\"First 5 false positive ratings identified from count vectorizer based multinomialNB Model is\",pd.DataFrame(X_test[y_test<y_predict_class_nb_CV].head()))\n",
    "print('_'*100)\n",
    "print(\"First 5 false positive ratings identified from TfidfVectorizer based multinomialNB Model is\",pd.DataFrame(X_test[y_test<y_predict_class_nb_TV].head()))\n",
    "print('_'*100)\n",
    "print(\"First 5 false positive ratings identified from count vectorizer based regression Model is\",pd.DataFrame(X_test[y_test<y_predict_class_logreg_CV].head()))\n",
    "print('_'*100)\n",
    "print(\"First 5 false positive ratings identified from TfidfVectorizer based regression Model is\",pd.DataFrame(X_test[y_test<y_predict_class_logreg_TV].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First 5 false negative ratings identified from count vectorizer based multinomialNB Model is',                                                    text\n",
      "7148  I now consider myself an Arizonian. If you dri...\n",
      "4963  This is by far my favourite department store, ...\n",
      "6318  Since I have ranted recently on poor customer ...\n",
      "380   This is a must try for any Mani Pedi fan. I us...\n",
      "5565  I`ve had work done by this shop a few times th...)\n",
      "____________________________________________________________________________________________________\n",
      "('First 5 false negative ratings identified from TfidfVectorizer based multinomialNB Model is', Empty DataFrame\n",
      "Columns: [text]\n",
      "Index: [])\n",
      "____________________________________________________________________________________________________\n",
      "('First 5 false negative ratings identified from count vectorizer based regression Model is',                                                    text\n",
      "8379  Greatness in the form of food, just like the o...\n",
      "6068  This review pertains to carnitas, and as such ...\n",
      "2164  I violated my rule of avoiding grocery shoppin...\n",
      "988   OK, so this is how much I love this product. I...\n",
      "1879  Totally worth the drive from Scottsdale. The f...)\n",
      "____________________________________________________________________________________________________\n",
      "('First 5 false negative ratings identified from TfidfVectorizer based regression Model is',                                                    text\n",
      "6318  Since I have ranted recently on poor customer ...\n",
      "2504  I've passed by prestige nails in walmart 100s ...\n",
      "2475  This place is so great! I am a nanny and had t...\n",
      "3442  This review is pretty much for the bra departm...\n",
      "3149  I was told to see Greg after a local shop diag...)\n"
     ]
    }
   ],
   "source": [
    "# first 5 false negatives (5-star reviews incorrectly classified as 1-star reviews)\n",
    "print(\"First 5 false negative ratings identified from count vectorizer based multinomialNB Model is\",pd.DataFrame(X_test[y_test>y_predict_class_nb_CV].head()))\n",
    "print('_'*100)\n",
    "print(\"First 5 false negative ratings identified from TfidfVectorizer based multinomialNB Model is\",pd.DataFrame(X_test[y_test>y_predict_class_nb_TV].head()))\n",
    "print('_'*100)\n",
    "print(\"First 5 false negative ratings identified from count vectorizer based regression Model is\",pd.DataFrame(X_test[y_test>y_predict_class_logreg_CV].head()))\n",
    "print('_'*100)\n",
    "print(\"First 5 false negative ratings identified from TfidfVectorizer based regression Model is\",pd.DataFrame(X_test[y_test>y_predict_class_logreg_TV].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Examining the naive based model for further insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16825\n",
      "____________________________________________________________________________________________________\n",
      "16825\n"
     ]
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens_CV = vect_CV.get_feature_names()\n",
    "print(len(X_train_tokens_CV))\n",
    "\n",
    "print('_'*100)\n",
    "X_train_tokens_TV = vect_TV.get_feature_names()\n",
    "print(len(X_train_tokens_TV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'00', u'000', u'00a', u'00am', u'00pm', u'01', u'02', u'03', u'03342', u'04', u'05', u'06', u'07', u'09', u'0buxoc0crqjpvkezo3bqog', u'0l', u'10', u'100', u'1000', u'1000x', u'1001', u'100th', u'101', u'102', u'105', u'1070', u'108', u'10am', u'10ish', u'10min']\n",
      "____________________________________________________________________________________________________\n",
      "[u'00', u'000', u'00a', u'00am', u'00pm', u'01', u'02', u'03', u'03342', u'04', u'05', u'06', u'07', u'09', u'0buxoc0crqjpvkezo3bqog', u'0l', u'10', u'100', u'1000', u'1000x', u'1001', u'100th', u'101', u'102', u'105', u'1070', u'108', u'10am', u'10ish', u'10min']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens_CV[0:30])\n",
    "print('_'*100)\n",
    "print(X_train_tokens_TV[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.  4.  1. ...  0.  0.  0.]\n",
      " [39.  5.  0. ...  1.  1.  1.]]\n",
      "____________________________________________________________________________________________________\n",
      "[[2.16150073 0.28760998 0.0417335  ... 0.         0.         0.        ]\n",
      " [3.67204717 0.30218985 0.         ... 0.13367213 0.04015155 0.12270144]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "#trailing_(underscore) means attributes that are estimated from the data\n",
    "print(nb_CV.feature_count_)\n",
    "print('_'*100)\n",
    "print(nb_TV.feature_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16825)\n",
      "____________________________________________________________________________________________________\n",
      "(2, 16825)\n"
     ]
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "print(nb_CV.feature_count_.shape)\n",
    "print('_'*100)\n",
    "print(nb_TV.feature_count_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('5 star rating/token(CV)', array([39.,  5.,  0., ...,  1.,  1.,  1.]))\n",
      "____________________________________________________________________________________________________\n",
      "('5 star rating/token(TV)', array([3.67204717, 0.30218985, 0.        , ..., 0.13367213, 0.04015155,\n",
      "       0.12270144]))\n"
     ]
    }
   ],
   "source": [
    "# number of times each token appears across 5 star\n",
    "five_token_count_CV = nb_CV.feature_count_[1, :]\n",
    "print(\"5 star rating/token(CV)\",five_token_count_CV)\n",
    "print('_'*100)\n",
    "five_token_count_TV = nb_TV.feature_count_[1, :]\n",
    "print(\"5 star rating/token(TV)\",five_token_count_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1 star rating/token(CV)', array([26.,  4.,  1., ...,  0.,  0.,  0.]))\n",
      "____________________________________________________________________________________________________\n",
      "('1 star rating/token(TV)', array([2.16150073, 0.28760998, 0.0417335 , ..., 0.        , 0.        ,\n",
      "       0.        ]))\n"
     ]
    }
   ],
   "source": [
    "# number of times each token appears across all 1 star\n",
    "one_token_count_CV = nb_CV.feature_count_[ 0,:]\n",
    "print(\"1 star rating/token(CV)\",one_token_count_CV)\n",
    "print('_'*100)\n",
    "one_token_count_TV =nb_TV.feature_count_[0, :]\n",
    "print(\"1 star rating/token(TV)\",one_token_count_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No. of observation/class (CV)', array([ 565., 2499.]))\n",
      "____________________________________________________________________________________________________\n",
      "('No. of observation/class (TV)', array([ 565., 2499.]))\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "# first number is one-star reviews, second number is five-star reviews\n",
    "print(\"No. of observation/class (CV)\",nb_CV.class_count_)\n",
    "print('_'*100)\n",
    "print(\"No. of observation/class (TV)\",nb_TV.class_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First 10 Tokens counted no. of times 1 star and 5 star from the data set (CV) ',        rating_1  rating_5\n",
      "token                    \n",
      "00         26.0      39.0\n",
      "000         4.0       5.0\n",
      "00a         1.0       0.0\n",
      "00am        3.0       2.0\n",
      "00pm        1.0       4.0\n",
      "01          1.0       2.0\n",
      "02          1.0       0.0\n",
      "03          1.0       0.0\n",
      "03342       1.0       0.0\n",
      "04          0.0       1.0)\n",
      "____________________________________________________________________________________________________\n",
      "('First 10 Tokens counted no. of times 1 star and 5 star from the data set (TV) ',        rating_1  rating_5\n",
      "token                    \n",
      "00     2.161501  3.672047\n",
      "000    0.287610  0.302190\n",
      "00a    0.041733  0.000000\n",
      "00am   0.216569  0.187216\n",
      "00pm   0.051069  0.337901\n",
      "01     0.031765  0.241645\n",
      "02     0.142078  0.000000\n",
      "03     0.102265  0.000000\n",
      "03342  0.075535  0.000000\n",
      "04     0.000000  0.101762)\n"
     ]
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate one-star and five-star counts\n",
    "tokens_CV = pd.DataFrame({'token':X_train_tokens_CV, 'rating_5':five_token_count_CV, 'rating_1': one_token_count_CV}).set_index('token')\n",
    "print(\"First 10 Tokens counted no. of times 1 star and 5 star from the data set (CV) \",\n",
    "      tokens_CV.head(10))\n",
    "print('_'*100)\n",
    "tokens_TV = pd.DataFrame({'token':X_train_tokens_TV, 'rating_5':five_token_count_TV, 'rating_1': one_token_count_TV}).set_index('token')\n",
    "print(\"First 10 Tokens counted no. of times 1 star and 5 star from the data set (TV) \",\n",
    "      tokens_TV.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rating_1  rating_5\n",
      "token                    \n",
      "00         27.0      40.0\n",
      "000         5.0       6.0\n",
      "00a         2.0       1.0\n",
      "00am        4.0       3.0\n",
      "00pm        2.0       5.0\n",
      "____________________________________________________________________________________________________\n",
      "       rating_1  rating_5\n",
      "token                    \n",
      "00     3.161501  4.672047\n",
      "000    1.287610  1.302190\n",
      "00a    1.041733  1.000000\n",
      "00am   1.216569  1.187216\n",
      "00pm   1.051069  1.337901\n"
     ]
    }
   ],
   "source": [
    "# add 1 to one-star and five-star counts to avoid dividing by 0\n",
    "tokens_CV['rating_1'] = tokens_CV.rating_1 +1\n",
    "tokens_CV['rating_5'] = tokens_CV.rating_5 +1\n",
    "print(tokens_CV.head())\n",
    "print('_'*100)\n",
    "tokens_TV['rating_1'] = tokens_TV.rating_1 +1\n",
    "tokens_TV['rating_5'] = tokens_TV.rating_5 +1\n",
    "print(tokens_TV.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rating_1  rating_5\n",
      "token                    \n",
      "00     0.047788  0.016006\n",
      "000    0.008850  0.002401\n",
      "00a    0.003540  0.000400\n",
      "00am   0.007080  0.001200\n",
      "00pm   0.003540  0.002001\n",
      "____________________________________________________________________________________________________\n",
      "       rating_1  rating_5\n",
      "token                    \n",
      "00     0.005596  0.001870\n",
      "000    0.002279  0.000521\n",
      "00a    0.001844  0.000400\n",
      "00am   0.002153  0.000475\n",
      "00pm   0.001860  0.000535\n"
     ]
    }
   ],
   "source": [
    "# convert the one-star and five-star counts into frequencies\n",
    "tokens_CV['rating_1'] = tokens_CV.rating_1/nb_CV.class_count_[0]\n",
    "tokens_CV['rating_5'] = tokens_CV.rating_5/nb_CV.class_count_[1]\n",
    "print(tokens_CV.head())\n",
    "print('_'*100)\n",
    "tokens_TV['rating_1'] = tokens_TV.rating_1/nb_TV.class_count_[0]\n",
    "tokens_TV['rating_5'] = tokens_TV.rating_5/nb_TV.class_count_[1]\n",
    "print(tokens_TV.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rating_1  rating_5  5_rating_ratio\n",
      "token                                    \n",
      "00     0.047788  0.016006        0.334949\n",
      "000    0.008850  0.002401        0.271309\n",
      "00a    0.003540  0.000400        0.113045\n",
      "00am   0.007080  0.001200        0.169568\n",
      "00pm   0.003540  0.002001        0.565226\n",
      "____________________________________________________________________________________________________\n",
      "       rating_1  rating_5  5_rating_ratio\n",
      "token                                    \n",
      "00     0.005596  0.001870        0.334115\n",
      "000    0.002279  0.000521        0.228651\n",
      "00a    0.001844  0.000400        0.217033\n",
      "00am   0.002153  0.000475        0.220635\n",
      "00pm   0.001860  0.000535        0.287790\n"
     ]
    }
   ],
   "source": [
    "# calculate the ratio of five-star to one-star for each token\n",
    "tokens_CV['5_rating_ratio'] = tokens_CV.rating_5/tokens_CV.rating_1\n",
    "print(tokens_CV.head())\n",
    "print('_'*100)\n",
    "tokens_TV['5_rating_ratio'] = tokens_TV.rating_5/tokens_TV.rating_1\n",
    "print(tokens_TV.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best tokens identified for 5 star rating(CV)',              rating_1  rating_5  5_rating_ratio\n",
      "token                                          \n",
      "fantastic    0.003540  0.077231       21.817727\n",
      "perfect      0.005310  0.098039       18.464052\n",
      "yum          0.001770  0.024810       14.017607\n",
      "favorite     0.012389  0.138055       11.143029\n",
      "outstanding  0.001770  0.019608       11.078431)\n",
      "____________________________________________________________________________________________________\n",
      "('Best tokens identified for 5 star rating(TV)',           rating_1  rating_5  5_rating_ratio\n",
      "token                                       \n",
      "great     0.006080  0.035167        5.783605\n",
      "love      0.004851  0.024487        5.047405\n",
      "amazing   0.002836  0.014302        5.042418\n",
      "favorite  0.002222  0.010756        4.839556\n",
      "awesome   0.002447  0.011576        4.731555)\n"
     ]
    }
   ],
   "source": [
    "# examine the DataFrame sorted by 5 star rating ratio\n",
    "tokens_best_CV = tokens_CV.sort_values('5_rating_ratio',ascending=False).head()\n",
    "print(\"Best tokens identified for 5 star rating(CV)\",tokens_best_CV)\n",
    "print('_'*100)\n",
    "tokens_best_TV = tokens_TV.sort_values('5_rating_ratio',ascending=False).head()\n",
    "print(\"Best tokens identified for 5 star rating(TV)\",tokens_best_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                rating_1  rating_5  5_rating_ratio\n",
      "token                                             \n",
      "staffperson     0.030088    0.0004        0.013299\n",
      "refused         0.024779    0.0004        0.016149\n",
      "disgusting      0.042478    0.0008        0.018841\n",
      "filthy          0.019469    0.0004        0.020554\n",
      "unprofessional  0.015929    0.0004        0.025121\n",
      "____________________________________________________________________________________________________\n",
      "            rating_1  rating_5  5_rating_ratio\n",
      "token                                         \n",
      "horrible    0.015383  0.000725        0.047143\n",
      "rude        0.010845  0.000654        0.060337\n",
      "gross       0.009410  0.000580        0.061591\n",
      "disgusting  0.006835  0.000460        0.067242\n",
      "worst       0.010059  0.000709        0.070478\n"
     ]
    }
   ],
   "source": [
    "print(tokens_CV.sort_values('5_rating_ratio',ascending=True).head())\n",
    "print('_'*100)\n",
    "print(tokens_TV.sort_values('5_rating_ratio',ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a16eb2850>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1943aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_CV.sort_values('5_rating_ratio',ascending=True).head(1000).hist('5_rating_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
